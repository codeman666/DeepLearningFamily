# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
# è¿™é‡Œæ˜¯ç‰ˆæƒå’Œé“¾æ¥ï¼Œå‘Šè¯‰ä½ è¿™ä»½é…ç½®è¦†ç›–äº†ï¼šè®­ç»ƒ / éªŒè¯ / é¢„æµ‹ / å¯¼å‡º / è·Ÿè¸ª çš„æ‰€æœ‰å¯ç”¨å‚æ•°ã€‚
# Global configuration YAML with settings and hyperparameters for YOLO training, validation, prediction and export
# For documentation see https://docs.ultralytics.com/usage/cfg/

# åŸºç¡€ä»»åŠ¡å’Œæ¨¡å¼
task: detect # (str) YOLO task, i.e. detect, segment, classify, pose, obb
mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
# æ¨¡å‹æ–‡ä»¶æˆ–ç»“æ„é…ç½®ï¼Œå¦‚ yolov8n.ptï¼ˆæƒé‡ï¼‰æˆ– yolov8n.yamlï¼ˆç»“æ„ï¼‰
model: # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
# æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼Œå¦‚ coco8.yamlï¼ˆé‡Œé¢æœ‰æ•°æ®è·¯å¾„ã€ç±»åˆ«ï¼‰
data: # (str, optional) path to data file, i.e. coco8.yaml
# è®­ç»ƒè½®æ•°
epochs: 100 # (int) number of epochs to train for
# è®­ç»ƒæ—¶é•¿ï¼ˆå°æ—¶ï¼‰ï¼Œå¦‚æœè®¾ç½®äº†å°±è¦†ç›– epochs
time: # (float, optional) number of hours to train for, overrides epochs if supplied
# Early Stoppingï¼Œå¤šå°‘è½®æ²¡æå‡å°±åœï¼Œè¿™ä¸ªå‚æ•°ä¸€èˆ¬ç”¨äºé˜²æ­¢è®­ç»ƒè¿‡åº¦æµªè´¹æ—¶é—´ï¼Œæˆ–è€…å‘ç”Ÿè¿‡æ‹Ÿåˆ
patience: 100 # (int) epochs to wait for no observable improvement for early stopping of training
# æ¯æ‰¹æ¬¡å›¾ç‰‡æ•°é‡ï¼ˆ-1 è¡¨ç¤ºè‡ªåŠ¨åŒ¹é…æ˜¾å­˜ï¼‰
batch: 16 # (int) number of images per batch (-1 for AutoBatch)
# è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆå¯ä»¥æ˜¯ int æˆ– [h, w]ï¼‰
imgsz: 640 # (int | list) input images size as int for train and val modes, or list[h,w] for predict and export modes
# æ˜¯å¦ä¿å­˜ä¸­é—´æƒé‡ã€ç»“æœå›¾
save: True # (bool) save train checkpoints and predict results
#  æ¯éš”å¤šå°‘è½®ä¿å­˜ä¸€æ¬¡æƒé‡ï¼Œ<1 è¡¨ç¤ºåªä¿å­˜æœ€ç»ˆæƒé‡
save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)
# æ˜¯å¦æŠŠæ•°æ®ç¼“å­˜åˆ°å†…å­˜ï¼ˆTrue/ramï¼‰ã€ç£ç›˜ï¼ˆdiskï¼‰ï¼Œæˆ– False
cache: False # (bool) True/ram, disk or False. Use cache for data loading
# æŒ‡å®šç”¨å“ªä¸ª GPUï¼Œæ¯”å¦‚ 0 æˆ– [0,1]ï¼Œæˆ– "cpu"
device: # (int | str | list) device: CUDA device=0 or [0,1,2,3] or "cpu/mps" or -1 or [-1,-1] to auto-select idle GPUs
# DataLoader çš„çº¿ç¨‹æ•°ï¼ˆDDP æ—¶æ¯ä¸ª RANK å„ç”¨å‡ ä¸ªï¼‰
workers: 8 # (int) number of worker threads for data loading (per RANK if DDP)
# é¡¹ç›®åï¼ˆç»“æœä¿å­˜åœ¨ runs/project/nameï¼‰
project: # (str, optional) project name
# å®éªŒåï¼ˆæ–‡ä»¶å¤¹åï¼‰
name: # (str, optional) experiment name, results saved to 'project/name' directory
# å·²å­˜åœ¨åŒåç›®å½•æ—¶æ˜¯å¦è¦†ç›–
exist_ok: False # (bool) whether to overwrite existing experiment
# æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆTrueï¼‰æˆ–æŒ‡å®šæ–‡ä»¶ï¼ˆå­—ç¬¦ä¸²ï¼‰
pretrained: True # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)
# ä¼˜åŒ–å™¨ï¼Œæ”¯æŒ SGDã€Adamã€AdamW ç­‰ï¼Œä¹Ÿå¯ä»¥è‡ªåŠ¨é€‰æ‹©
optimizer: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
# æ˜¯å¦æ‰“å°è¯¦ç»†è®­ç»ƒæ—¥å¿—
verbose: True # (bool) whether to print verbose output
# éšæœºç§å­ï¼Œç”¨äºåˆå§‹åŒ–æƒé‡ï¼Œæ•°æ®å¢å¼ºã€æ•°æ®åŠ è½½ã€Dropout
seed: 0 # (int) random seed for reproducibility
# è¡¨ç¤ºæ˜¯å¦å¯ç”¨ ç¡®å®šæ€§ç®—æ³•ï¼Œç¡®ä¿åœ¨ç›¸åŒè¾“å…¥å’Œç›¸åŒéšæœºç§å­ä¸‹ï¼Œæ¨¡å‹çš„æ¯æ¬¡è¿è¡Œç»“æœå®Œå…¨ä¸€è‡´ï¼Œä¿è¯è®­ç»ƒçš„å¯é‡å¤æ€§ã€‚
deterministic: True # (bool) whether to enable deterministic mode
# å¤šç±»åˆ«æ£€æµ‹æˆ–è€…å•ç±»åˆ«æ£€æµ‹ï¼ˆå¤šç±»åˆæˆä¸€ç±»ï¼‰
single_cls: False # (bool) train multi-class data as single-class
# åœ¨æ¨ç†ï¼ˆæ£€æµ‹ï¼‰æ—¶ï¼Œæ˜¯å¦ä½¿ç”¨çŸ©å½¢è£å‰ªå’Œç¼©æ”¾ä¿æŒå›¾ç‰‡çš„å®½é«˜æ¯”ã€‚
rect: False # (bool) rectangular training if mode='train' or rectangular validation if mode='val'
# æ˜¯å¦ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡
cos_lr: False # (bool) use cosine learning rate scheduler
# è®­ç»ƒæ—¶ï¼Œæ˜¯å¦ä½¿ç”¨ Mosaic æ•°æ®å¢å¼º
close_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)
# æ˜¯å¦ä»æœ€è¿‘ä¸€æ¬¡ checkpoint æ¢å¤è®­ç»ƒï¼Œè®­ç»ƒè¿‡ç¨‹æ˜¯å¦ä»ä¸Šä¸€æ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­
resume: False # (bool) resume training from last checkpoint
# æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰
amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
# # ä½¿ç”¨æ•°æ®é›†æ¯”ä¾‹ï¼ˆ1.0=å…¨éƒ¨ï¼Œ0.5=ä¸€åŠï¼‰
fraction: 1.0 # (float) dataset fraction to train on (default is 1.0, all images in train set)
# # æ˜¯å¦åœ¨è®­ç»ƒæ—¶ Profile ONNXã€TensorRT å¯¼å‡º
profile: False # (bool) profile ONNX and TensorRT speeds during training for loggers
# å†»ç»“å‰å¤šå°‘å±‚ï¼ˆintï¼‰æˆ–æŒ‡å®šå±‚ index åˆ—è¡¨ï¼Œå¯ä»¥æŒ‡å®šå±‚æ•°
freeze: # (int | list, optional) freeze first n layers, or freeze list of layer indices during training
# æ˜¯å¦ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒ
multi_scale: False # (bool) Whether to use multiscale during training
# Segmentation
overlap_mask: True # (bool) merge object masks into a single image mask during training (segment train only)
mask_ratio: 4 # (int) mask downsample ratio (segment train only)
# Classification
# Dropout æ¦‚ç‡ï¼ˆä»…åˆ†ç±»ï¼‰
dropout: 0.0 # (float) use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
# æ˜¯å¦åœ¨è®­ç»ƒæ—¶åšéªŒè¯
val: True # (bool) validate/test during training
# split æŒ‡çš„æ˜¯æ•°æ®é›†åˆ’åˆ†ï¼Œå³ä½ é€‰æ‹©ç”¨å“ªä¸ªå­é›†æ¥è¿›è¡Œå½“å‰æ“ä½œã€‚
split: val # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
# æ˜¯å¦ä¿å­˜ç»“æœä¸º COCO JSON
save_json: False # (bool) save results to JSON file
# ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ¨ç†é»˜è®¤ 0.25ï¼ŒéªŒè¯é»˜è®¤ 0.001ï¼‰
conf: # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
# NMS é˜ˆå€¼ï¼ˆIoUï¼‰
iou: 0.7 # (float) intersection over union (IoU) threshold for NMS
# æ¯å¼ å›¾æœ€å¤§æ£€æµ‹ç›®æ ‡æ•°
max_det: 300 # (int) maximum number of detections per image
# æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ï¼ˆFP16ï¼‰
half: False # (bool) use half precision (FP16)
# æ˜¯å¦ä½¿ç”¨ OpenCV DNNï¼ˆONNX ç”¨ï¼‰
dnn: False # (bool) use OpenCV DNN for ONNX inference
# æ˜¯å¦ä¿å­˜éªŒè¯å›¾ã€æ··æ·†çŸ©é˜µï¼Œæ˜¯å¦åœ¨éªŒè¯ï¼ˆvalidationï¼‰é˜¶æ®µä¿å­˜ä¸€äº›å¯è§†åŒ–å›¾è¡¨
plots: True # (bool) save plots and images during train/val

# Predict settings -----------------------------------------------------------------------------------------------------
# é¢„æµ‹æº
source: # (str, optional) source directory for images or videos
# è§†é¢‘å¤„ç†æ—¶é‡‡æ ·å¸§çš„é—´éš”ï¼Œä¹Ÿå°±æ˜¯è·³å¸§ç‡ã€‚vid_stride: 1 è¡¨ç¤ºå¤„ç†è§†é¢‘æ—¶æ¯ä¸€å¸§éƒ½ä½¿ç”¨ï¼ˆä¸è·³å¸§ï¼‰
vid_stride: 1 # (int) video frame-rate stride
# å¦‚æœä½ æƒ³åšå®æ—¶æ£€æµ‹ï¼Œæ¨è stream_buffer: Falseã€‚
# å¦‚æœä½ æƒ³ä¿å­˜å®Œæ•´å¸§åºåˆ—ï¼Œåšåç»­å¤æ‚åˆ†æï¼Œé€‰ Trueã€‚
stream_buffer: False # (bool) buffer all streaming frames (True) or return the most recent frame (False)
# æ˜¯å¦å¯è§†åŒ–ç‰¹å¾
visualize: False # (bool) visualize model features
# æ˜¯å¦å¯ç”¨æ¨ç†æ—¶çš„æ•°æ®å¢å¼º
augment: False # (bool) apply image augmentation to prediction sources
# ç±»åˆ«æ— å…³çš„ NMS
#False è¡¨ç¤ºä½¿ç”¨ç±»åˆ«ç›¸å…³çš„ NMSï¼Œå³åœ¨æ‰§è¡Œ NMS æ—¶ï¼Œä¸åŒç±»åˆ«çš„æ£€æµ‹æ¡†ä¸ä¼šç›¸äº’å½±å“ã€‚
#True è¡¨ç¤ºä½¿ç”¨ç±»åˆ«æ— å…³çš„ NMSï¼Œæ‰€æœ‰ç±»åˆ«çš„æ£€æµ‹æ¡†éƒ½ä¸€èµ·å‚ä¸ NMSï¼Œä¸ç®¡ç±»åˆ«ã€‚
agnostic_nms: False # (bool) class-agnostic NMS
# # åªæ£€æµ‹å“ªäº›ç±»åˆ«ï¼ˆå¦‚ classes=0 æˆ– [0,2,3]ï¼‰
classes: # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]
retina_masks: False # (bool) use high-resolution segmentation masks
embed: # (list[int], optional) return feature vectors/embeddings from given layers

# Visualize settings ---------------------------------------------------------------------------------------------------
# å¯è§†åŒ–è®¾ç½®
# æ¨ç†æ—¶æ˜¯å¦å¼¹çª—æ˜¾ç¤ºç»“æœ
show: False # (bool) show predicted images and videos if environment allows
# æ˜¯å¦ä¿å­˜è§†é¢‘å¸§
save_frames: False # (bool) save predicted individual video frames
# æ˜¯å¦ä¿å­˜æ£€æµ‹æ¡†åˆ° .txt
save_txt: False # (bool) save results as .txt file
# æ˜¯å¦ä¿å­˜ç½®ä¿¡åº¦
save_conf: False # (bool) save results with confidence scores
# æ˜¯å¦ä¿å­˜è£å‰ªåçš„ç›®æ ‡
save_crop: False # (bool) save cropped images with results
# æ˜¯å¦æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾
show_labels: True # (bool) show prediction labels, i.e. 'person'
# æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
show_conf: True # (bool) show prediction confidence, i.e. '0.99'
# æ˜¯å¦æ˜¾ç¤ºæ¡†
show_boxes: True # (bool) show prediction boxes
# æ£€æµ‹æ¡†çº¿å®½ï¼ˆNone è¡¨ç¤ºè‡ªé€‚åº”ï¼‰
line_width: # (int, optional) line width of the bounding boxes. Scaled to image size if None.

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats
keras: False # (bool) use Kera=s
optimize: False # (bool) TorchScript: optimize for mobile
int8: False # (bool) CoreML/TF INT8 quantization
dynamic: False # (bool) ONNX/TF/TensorRT: dynamic axes
simplify: True # (bool) ONNX: simplify model using `onnxslim`
opset: # (int, optional) ONNX: opset version
workspace: # (float, optional) TensorRT: workspace size (GiB), `None` will let TensorRT auto-allocate memory
nms: False # (bool) CoreML: add NMS

# æ ¸å¿ƒè¶…å‚æ•°
# Hyperparameters ------------------------------------------------------------------------------------------------------
# åˆå§‹å­¦ä¹ ç‡ï¼ˆSGD 1e-2ï¼ŒAdam 1e-3ï¼‰
lr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
# æœ€ç»ˆå­¦ä¹ ç‡ï¼ˆlr0 * lrfï¼‰
lrf: 0.01 # (float) final learning rate (lr0 * lrf)
# SGD åŠ¨é‡ / Adam beta1
momentum: 0.937 # (float) SGD momentum/Adam beta1
# æƒé‡è¡°å‡
weight_decay: 0.0005 # (float) optimizer weight decay 5e-4
# é¢„çƒ­è½®æ•°
warmup_epochs: 3.0 # (float) warmup epochs (fractions ok)
# é¢„çƒ­é˜¶æ®µåŠ¨é‡
warmup_momentum: 0.8 # (float) warmup initial momentum
# é¢„çƒ­é˜¶æ®µåç½®å­¦ä¹ ç‡
warmup_bias_lr: 0.1 # (float) warmup initial bias lr
box: 7.5 # (float) box loss gain
cls: 0.5 # (float) cls loss gain (scale with pixels)
dfl: 1.5 # (float) dfl loss gain
pose: 12.0 # (float) pose loss gain
kobj: 1.0 # (float) keypoint obj loss gain
nbs: 64 # (int) nominal batch size
hsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)
hsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)
hsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)
degrees: 0.0 # (float) image rotation (+/- deg)
translate: 0.1 # (float) image translation (+/- fraction)
scale: 0.5 # (float) image scale (+/- gain)
shear: 0.0 # (float) image shear (+/- deg)
perspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001
flipud: 0.0 # (float) image flip up-down (probability)
fliplr: 0.5 # (float) image flip left-right (probability)
bgr: 0.0 # (float) image channel BGR (probability)
mosaic: 1.0 # (float) image mosaic (probability)
mixup: 0.0 # (float) image mixup (probability)
cutmix: 0.0 # (float) image cutmix (probability)
copy_paste: 0.0 # (float) segment copy-paste (probability)
copy_paste_mode: "flip" # (str) the method to do copy_paste augmentation (flip, mixup)
auto_augment: randaugment # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)
erasing: 0.4 # (float) probability of random erasing during classification training (0-0.9), 0 means no erasing, must be less than 1.0.

# Custom config.yaml ---------------------------------------------------------------------------------------------------
# è¦†ç›–é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„æ¯”å¦‚ï¼šmodels/yolov8n.yaml æˆ– configs/my_custom.yaml
cfg: # (str, optional) for overriding defaults.yaml

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]
